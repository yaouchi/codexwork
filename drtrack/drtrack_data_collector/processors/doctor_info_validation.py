"""
åŒ»å¸«æƒ…å ±æ¤œè¨¼ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆç‹¬ç«‹å®Ÿè£…ç‰ˆï¼‰

doctor_info.pyã®å‡ºåŠ›TSVã‚’æ¤œè¨¼ã—ã€å“è³ªå‘ä¸Šã‚’å›³ã‚‹
doctor_info.pyã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å®Ÿè£…
"""

import os
import io
import re
import asyncio
import pandas as pd
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
import time
import google.generativeai as genai

from config import Config, LOCAL_TEST
from common.logger import UnifiedLogger
from common.gcs_client import UnifiedGCSClient
from common.ai_client import UnifiedAIClient
from common.http_client import UnifiedHttpClient


@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœ"""
    validation_status: str
    validation_message: str
    corrected_name: str
    corrected_department: str
    corrected_position: str
    corrected_specialty: str
    corrected_licence: str
    corrected_others: str
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    ai_response_raw: str = ""
    parsing_attempts: List[str] = field(default_factory=list)
    html_excerpt: str = ""
    processing_time: float = 0.0


class DoctorInfoValidationProcessor:
    """åŒ»å¸«æƒ…å ±æ¤œè¨¼ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆç‹¬ç«‹å®Ÿè£…ï¼‰"""
    
    def __init__(self, config: Config, logger: UnifiedLogger):
        self.config = config
        self.logger = logger
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.gcs_client = UnifiedGCSClient(config, logger)
        self.ai_client = UnifiedAIClient(config, logger)
        self.http_client = None
        
        # è¨­å®šå€¤ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—å¯èƒ½ï¼‰
        self.batch_size = int(os.getenv('VALIDATION_BATCH_SIZE', '5'))
        self.max_chars = int(os.getenv('VALIDATION_MAX_CHARS', '30000'))
        # AIæ¸©åº¦ã‚’0.0ã«è¨­å®šã—ã¦å®Œå…¨ã«æ±ºå®šçš„ãªå‡ºåŠ›ã«ã™ã‚‹
        self.ai_temperature = float(os.getenv('VALIDATION_AI_TEMPERATURE', '0.0'))
        self.debug_mode = os.getenv('VALIDATION_DEBUG_MODE', 'true').lower() == 'true'
        
        # å‡¦ç†çµæœ
        self.all_records = []
        self.validation_stats = {
            'total_processed': 0,
            'valid_count': 0,
            'partial_count': 0,
            'invalid_count': 0,
            'notfound_count': 0,
            'parsing_failures': 0,
            'processing_errors': 0,
            'natural_language_extractions': 0  # è‡ªç„¶è¨€èªæŠ½å‡ºã®ä½¿ç”¨å›æ•°ã‚’è¿½è·¡
        }
    
    async def run_async(self):
        """éåŒæœŸå®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        try:
            self.logger.log_info("=== åŒ»å¸«æƒ…å ±æ¤œè¨¼å‡¦ç†é–‹å§‹ï¼ˆç‹¬ç«‹å®Ÿè£…ç‰ˆï¼‰ ===")
            
            # doctor_info ãƒ•ã‚©ãƒ«ãƒ€ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            input_data = await self._read_tsv_files_from_gcs()
            
            if input_data.empty:
                self.logger.log_warning("å‡¦ç†å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # ã‚¿ã‚¹ã‚¯åˆ†å‰²
            task_data = self.gcs_client.get_task_data(input_data)
            self.logger.log_info(f"æ¤œè¨¼å¯¾è±¡: {len(task_data)}ä»¶")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿
            prompt = await self._read_prompt_from_gcs()
            
            # HTTP Clientã‚’ä½¿ç”¨ã—ãŸéåŒæœŸå‡¦ç†ï¼ˆdoctor_info.pyãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            async with UnifiedHttpClient(self.config, self.logger) as http_client:
                self.http_client = http_client
                
                # ãƒãƒƒãƒå‡¦ç†ã§æ¤œè¨¼å®Ÿè¡Œ
                for i in range(0, len(task_data), self.batch_size):
                    batch_df = task_data.iloc[i:i + self.batch_size]
                    await self._process_batch_async(batch_df, prompt)
                    
                    self.logger.log_info(f"ãƒãƒƒãƒ {i // self.batch_size + 1} å®Œäº†: {len(batch_df)}ä»¶")
                    
                    # ãƒãƒƒãƒé–“éš”
                    await asyncio.sleep(0.5)
            
            # çµæœä¿å­˜
            if self.all_records:
                await self._save_validation_results()
            
            self._log_final_statistics()
            self.logger.log_info("=== åŒ»å¸«æƒ…å ±æ¤œè¨¼å‡¦ç†å®Œäº† ===")
            
        except Exception as e:
            self.logger.log_error(f"åŒ»å¸«æƒ…å ±æ¤œè¨¼å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            raise
    
    def run_sync(self):
        """åŒæœŸå®Ÿè¡Œ"""
        return asyncio.run(self.run_async())
    
    async def _read_tsv_files_from_gcs(self) -> pd.DataFrame:
        """GCSã‹ã‚‰doctor_info/tsv/ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # doctor_info ãƒ•ã‚©ãƒ«ãƒ€ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            bucket_name = self.config.input_bucket
            prefix = 'doctor_info/tsv/'
            
            # GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç›´æ¥ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            bucket = self.gcs_client.storage_client.bucket(bucket_name)
            blobs = [blob.name for blob in bucket.list_blobs(prefix=prefix)]
            
            all_data = []
            for blob_name in blobs:
                if blob_name.endswith('.tsv'):
                    # GCSã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    blob = bucket.blob(blob_name)
                    content = blob.download_as_text(encoding='utf-8')
                    
                    # TSVã‚’DataFrameã«å¤‰æ›
                    df = pd.read_csv(
                        io.StringIO(content),
                        sep='\t',
                        dtype=str,
                        na_filter=False
                    )
                    
                    if not df.empty:
                        all_data.append(df)
                        self.logger.log_info(f"TSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {blob_name} ({len(df)}è¡Œ)")
            
            if not all_data:
                self.logger.log_warning("èª­ã¿è¾¼ã¿å¯èƒ½ãªTSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return pd.DataFrame()
            
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            combined_data = pd.concat(all_data, ignore_index=True)
            
            # åˆ—åæ­£è¦åŒ–ï¼ˆurl â†’ URLï¼‰
            if 'url' in combined_data.columns and 'URL' not in combined_data.columns:
                combined_data = combined_data.rename(columns={'url': 'URL'})
                self.logger.log_info("åˆ—åã‚’æ­£è¦åŒ–: url -> URL")
            
            self.logger.log_success(f"å…¥åŠ›ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(combined_data)}è¡Œ")
            
            return combined_data
            
        except Exception as e:
            self.logger.log_error(f"TSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    async def _read_prompt_from_gcs(self) -> str:
        """æ¤œè¨¼å°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # æ¤œè¨¼å°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆæ­£ã—ã„ãƒ‘ã‚¹ï¼‰
            bucket_name = self.config.input_bucket
            prompt_path = f'{self.config.job_type}/input/prompt.txt'  # doctor_info_validation/input/prompt.txt
            
            bucket = self.gcs_client.storage_client.bucket(bucket_name)
            blob = bucket.blob(prompt_path)
            
            if blob.exists():
                content = blob.download_as_text(encoding='utf-8')
                self.logger.log_success(f"æ¤œè¨¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {len(content)}æ–‡å­—")
                return content
            else:
                self.logger.log_warning(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: gs://{bucket_name}/{prompt_path}")
                
        except Exception as e:
            self.logger.log_error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        return """ã‚ãªãŸã¯åŒ»ç™‚æ©Ÿé–¢ã®å°‚é–€åŒ»æƒ…å ±ã‚’æ¤œè¨¼ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®åŒ»å¸«æƒ…å ±ãŒWebãƒšãƒ¼ã‚¸ã«å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‹ã€è¨˜è¼‰å†…å®¹ãŒæ­£ã—ã„ã‹ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚

å¿…ãšä»¥ä¸‹ã®TSVå½¢å¼ï¼ˆã‚¿ãƒ–åŒºåˆ‡ã‚Šï¼‰ã§1è¡Œã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
validation_status[TAB]validation_message[TAB]corrected_name[TAB]corrected_department[TAB]corrected_position[TAB]corrected_specialty[TAB]corrected_licence[TAB]corrected_others

æ¤œè¨¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:
- VALID: åŒ»å¸«åã¨è¨ºç™‚ç§‘ãŒæ­£ã—ãã€ä»–ã®é …ç›®ã‚‚æ¦‚ã­æ­£ã—ã„
- PARTIAL: åŒ»å¸«ã¯å­˜åœ¨ã—åå‰ã¨è¨ºç™‚ç§‘ã¯åˆã£ã¦ã„ã‚‹ãŒã€ä»–ã®é …ç›®ã«ç›¸é•ã‚„æ¬ è½ãŒã‚ã‚‹
- INVALID: è©²å½“åŒ»å¸«ãŒHTMLã«å…¨ãå­˜åœ¨ã—ãªã„
- NOTFOUND: æŠ€è¡“çš„ç†ç”±ã§æ¤œè¨¼ä¸å¯
"""
    
    async def _process_batch_async(self, batch_df: pd.DataFrame, prompt: str):
        """ãƒãƒƒãƒéåŒæœŸå‡¦ç†ï¼ˆdoctor_info.pyãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰"""
        semaphore = asyncio.Semaphore(self.config.max_concurrent_requests)
        
        tasks = []
        for _, row in batch_df.iterrows():
            task = self._process_single_record_async(row, prompt, semaphore)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # çµæœå‡¦ç†
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.log_error(f"ãƒ¬ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(result)}")
                self.validation_stats['processing_errors'] += 1
                row = batch_df.iloc[i]
                error_result = self._create_error_result(row, str(result))
                self.all_records.extend(error_result)
            elif result:
                self.all_records.extend(result)
    
    async def _process_single_record_async(
        self, 
        record: pd.Series, 
        prompt: str, 
        semaphore: asyncio.Semaphore
    ) -> List[Dict[str, Any]]:
        """å˜ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰éåŒæœŸå‡¦ç†ï¼ˆdoctor_info.pyãƒ‘ã‚¿ãƒ¼ãƒ³æº–æ‹ ï¼‰"""
        start_time = time.time()
        
        async with semaphore:
            try:
                url = record.get('URL', '')
                fac_id_unif = record.get('fac_id_unif', '')
                
                if not url:
                    self.logger.log_warning(f"URLæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fac_id_unif}")
                    return self._create_error_result(record, "URLä¸æ˜")
                
                # HTMLå–å¾—ï¼ˆdoctor_info.pyãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                html_content = await self.http_client.fetch_html_async(url)
                if not html_content:
                    return self._create_error_result(record, "HTMLå–å¾—å¤±æ•—")
                
                # HTMLå‰å‡¦ç†ï¼ˆdoctor_info.pyãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                processed_content = self.http_client.preprocess_html(html_content)
                if not processed_content.strip():
                    return self._create_error_result(record, "HTMLå‰å‡¦ç†å¾Œã«ç©º")
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šï¼ˆdoctor_info.pyãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                context = {
                    'url': url,
                    'fac_id_unif': fac_id_unif
                }
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆåŒ»å¸«æƒ…å ±ã‚’çµ„ã¿è¾¼ã¿ï¼‰
                enhanced_prompt = self._generate_enhanced_prompt(record, prompt)
                
                # AIæ¤œè¨¼å®Ÿè¡Œï¼ˆæ¤œè¨¼å°‚ç”¨å‡¦ç† - ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—ï¼‰
                raw_ai_response = self._call_ai_for_validation(
                    processed_content,
                    enhanced_prompt
                )
                
                if not raw_ai_response:
                    return self._create_error_result(record, "AIå¿œç­”ãªã—")
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æï¼ˆ5æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                validation_result = self._parse_ai_response_robust(
                    raw_ai_response, 
                    record
                )
                
                # çµ±è¨ˆæ›´æ–°
                self._update_validation_statistics(validation_result.validation_status)
                self.validation_stats['total_processed'] += 1
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¨­å®š
                validation_result.processing_time = time.time() - start_time
                validation_result.ai_response_raw = str(raw_ai_response)
                if len(processed_content) > 500:
                    validation_result.html_excerpt = processed_content[:500] + "..."
                else:
                    validation_result.html_excerpt = processed_content
                
                # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
                if self.debug_mode:
                    self._log_validation_attempt(record, validation_result)
                
                return [self._validation_result_to_dict(record, validation_result)]
                
            except Exception as e:
                self.logger.log_error(f"ãƒ¬ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                return self._create_error_result(record, str(e))
    
    def _generate_enhanced_prompt(self, record: pd.Series, base_prompt: str) -> str:
        """åŒ»å¸«æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚“ã ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        try:
            # åŒ»å¸«æƒ…å ±ã‚’å–å¾—
            name = record.get('name', '')
            department = record.get('department', '')
            position = record.get('position', '')
            specialty = record.get('specialty', '')
            licence = record.get('licence', '')
            others = record.get('others', '')
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
            enhanced_prompt = base_prompt.format(
                name=name,
                department=department,
                position=position,
                specialty=specialty,
                licence=licence,
                others=others
            )
            
            return enhanced_prompt
            
        except Exception as e:
            self.logger.log_warning(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ‰‹å‹•ã§ç½®æ›
            try:
                enhanced_prompt = base_prompt.replace('{name}', str(name))
                enhanced_prompt = enhanced_prompt.replace('{department}', str(department))
                enhanced_prompt = enhanced_prompt.replace('{position}', str(position))
                enhanced_prompt = enhanced_prompt.replace('{specialty}', str(specialty))
                enhanced_prompt = enhanced_prompt.replace('{licence}', str(licence))
                enhanced_prompt = enhanced_prompt.replace('{others}', str(others))
                return enhanced_prompt
            except:
                return base_prompt
    
    def _call_ai_for_validation(self, content: str, prompt: str) -> str:
        """æ¤œè¨¼å°‚ç”¨AIå‡¦ç†ï¼ˆç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹æ–‡å­—åˆ—ã‚’è¿”ã™ï¼‰"""
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆæ™‚ã¯ãƒ¢ãƒƒã‚¯å¿œç­”ï¼ˆæœ€å„ªå…ˆãƒã‚§ãƒƒã‚¯ï¼‰
            if LOCAL_TEST:
                self.logger.log_info("ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: ãƒ¢ãƒƒã‚¯æ¤œè¨¼å¿œç­”ã‚’è¿”ã—ã¾ã™")
                return "VALID\tæ¤œè¨¼æˆåŠŸ\tåŒ»å¸«å\tè¨ºç™‚ç§‘\téƒ¨é•·\tå°‚é–€åˆ†é‡\tè³‡æ ¼\tãã®ä»–æƒ…å ±"
            
            # AI Clientã®modelå­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if not hasattr(self.ai_client, 'model') or self.ai_client.model is None:
                self.logger.log_error("AI Clientã®modelæœªåˆæœŸåŒ–")
                return "NOTFOUND\tæŠ€è¡“çš„ã‚¨ãƒ©ãƒ¼\t\t\t\t\t\t"
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚ºåˆ¶é™
            if len(content) > self.max_chars:
                content = content[:self.max_chars]
                self.logger.log_warning(f"æ¤œè¨¼ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ: {self.max_chars}æ–‡å­—")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
            full_prompt = f"{prompt}\n\nHTML:\n{content}"
            
            # AIç”Ÿæˆå®Ÿè¡Œï¼ˆå®Œå…¨æ±ºå®šçš„è¨­å®šï¼‰
            response = self.ai_client.model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.0,        # å®Œå…¨æ±ºå®šçš„
                    top_p=0.1,             # æœ€å°å€¤
                    top_k=1,               # æœ€ä¸Šä½ã®ã¿é¸æŠ
                    max_output_tokens=256, # çŸ­ã„å‡ºåŠ›ã«åˆ¶é™ï¼ˆTSV1è¡Œã®ã¿å¿…è¦ï¼‰
                    candidate_count=1      # å€™è£œæ•°ã‚’1ã«é™å®š
                )
            )
            
            ai_response_text = response.text if response.text else ""
            
            # ğŸ” AIã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è©³ç´°ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            self.logger.log_info(
                f"ğŸ¤– AIç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°:",
                response_length=len(ai_response_text),
                response_preview=ai_response_text[:200] if ai_response_text else "(ç©º)",
                response_full=ai_response_text,  # å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¨˜éŒ²
                contains_tab='\t' in ai_response_text,
                contains_newline='\n' in ai_response_text,
                starts_with_status=ai_response_text[:10] if ai_response_text else "",
                line_count=ai_response_text.count('\n') + 1 if ai_response_text else 0
            )
            
            return ai_response_text
            
        except Exception as e:
            self.logger.log_error(f"æ¤œè¨¼ç”¨AIå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return "NOTFOUND\tå‡¦ç†ã‚¨ãƒ©ãƒ¼\t\t\t\t\t\t"
    
    def _parse_ai_response_robust(self, response_text: str, original_record: pd.Series) -> ValidationResult:
        """å …ç‰¢ãªAIãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æï¼ˆ5æ®µéšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        parsing_attempts = []
        
        # ğŸ” è§£æé–‹å§‹ã®è©³ç´°ãƒ­ã‚°
        self.logger.log_info(
            f"ğŸ“Š AIãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æé–‹å§‹:",
            doctor_name=original_record.get('name', ''),
            response_type=type(response_text).__name__,
            response_length=len(str(response_text)),
            response_raw=str(response_text)[:100] + "..." if len(str(response_text)) > 100 else str(response_text)
        )
        
        # AIå¿œç­”ãŒDictå½¢å¼ã®å ´åˆã®å‡¦ç†
        if isinstance(response_text, dict):
            response_text = response_text.get('content', str(response_text))
        elif not isinstance(response_text, str):
            response_text = str(response_text)
        
        # ç¬¬1æ®µéš: æ¨™æº–TSVè§£æï¼ˆã‚¿ãƒ–åŒºåˆ‡ã‚Šï¼‰
        try:
            self.logger.log_info("ğŸ” ç¬¬1æ®µéš: ã‚¿ãƒ–åŒºåˆ‡ã‚Šè§£æã‚’è©¦è¡Œ")
            result = self._try_tab_separated_parsing(response_text)
            if result:
                parsing_attempts.append("tab_separated")
                result.parsing_attempts = parsing_attempts
                self.logger.log_success("âœ… ã‚¿ãƒ–åŒºåˆ‡ã‚Šè§£ææˆåŠŸ")
                return result
        except Exception as e:
            parsing_attempts.append(f"tab_separated_failed: {str(e)}")
            self.logger.log_warning(f"âŒ ã‚¿ãƒ–åŒºåˆ‡ã‚Šè§£æå¤±æ•—: {str(e)}")
        
        # ç¬¬2æ®µéš: ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šè§£æ
        try:
            self.logger.log_info("ğŸ” ç¬¬2æ®µéš: ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šè§£æã‚’è©¦è¡Œ")
            result = self._try_space_separated_parsing(response_text)
            if result:
                parsing_attempts.append("space_separated")
                result.parsing_attempts = parsing_attempts
                self.logger.log_success("âœ… ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šè§£ææˆåŠŸ")
                return result
        except Exception as e:
            parsing_attempts.append(f"space_separated_failed: {str(e)}")
            self.logger.log_warning(f"âŒ ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šè§£æå¤±æ•—: {str(e)}")
        
        # ç¬¬3æ®µéš: æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹è§£æ
        try:
            self.logger.log_info("ğŸ” ç¬¬3æ®µéš: æ­£è¦è¡¨ç¾è§£æã‚’è©¦è¡Œ")
            result = self._try_regex_parsing(response_text)
            if result:
                parsing_attempts.append("regex_based")
                result.parsing_attempts = parsing_attempts
                self.logger.log_success("âœ… æ­£è¦è¡¨ç¾è§£ææˆåŠŸ")
                return result
        except Exception as e:
            parsing_attempts.append(f"regex_failed: {str(e)}")
            self.logger.log_warning(f"âŒ æ­£è¦è¡¨ç¾è§£æå¤±æ•—: {str(e)}")
        
        # ç¬¬4æ®µéš: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šè§£æ
        try:
            self.logger.log_info("ğŸ” ç¬¬4æ®µéš: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šè§£æã‚’è©¦è¡Œ")
            result = self._try_comma_separated_parsing(response_text)
            if result:
                parsing_attempts.append("comma_separated")
                result.parsing_attempts = parsing_attempts
                self.logger.log_success("âœ… ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šè§£ææˆåŠŸ")
                return result
        except Exception as e:
            parsing_attempts.append(f"comma_separated_failed: {str(e)}")
            self.logger.log_warning(f"âŒ ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šè§£æå¤±æ•—: {str(e)}")
        
        # ç¬¬5æ®µéš: è‡ªç„¶è¨€èªå‡¦ç†ã«ã‚ˆã‚‹æƒ…å ±æŠ½å‡ºï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
        self.logger.log_warning(
            f"âš ï¸ å…¨è§£ææ‰‹æ³•å¤±æ•— - è‡ªç„¶è¨€èªæŠ½å‡ºã«ç§»è¡Œ:",
            doctor_name=original_record.get('name', ''),
            failed_attempts=parsing_attempts,
            ai_response_problematic=response_text
        )
        
        try:
            result = self._try_natural_language_extraction(response_text, original_record)
            if result:
                parsing_attempts.append("natural_language")
                result.parsing_attempts = parsing_attempts
                return result
        except Exception as e:
            parsing_attempts.append(f"natural_language_failed: {str(e)}")
        
        # æœ€çµ‚æ®µéš: è§£æå¤±æ•—
        self.validation_stats['parsing_failures'] += 1
        self._log_parsing_failure(response_text, parsing_attempts)
        
        return ValidationResult(
            validation_status="NOTFOUND",
            validation_message="è§£æå¤±æ•—",
            corrected_name=original_record.get('name', ''),
            corrected_department=original_record.get('department', ''),
            corrected_position="",
            corrected_specialty="",
            corrected_licence="",
            corrected_others="",
            ai_response_raw=response_text,
            parsing_attempts=parsing_attempts
        )
    
    def _try_tab_separated_parsing(self, response_text: str) -> Optional[ValidationResult]:
        """ç¬¬1æ®µéš: ã‚¿ãƒ–åŒºåˆ‡ã‚Šè§£æ"""
        lines = response_text.strip().split('\n')
        for line in lines:
            if '\t' in line:
                parts = line.split('\t')
                if len(parts) >= 3:  # æœ€ä½é™ status, message, name ãŒã‚ã‚Œã°å‡¦ç†
                    # 8å€‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«åˆã‚ã›ã¦ä¸è¶³åˆ†ã‚’ç©ºæ–‡å­—ã§åŸ‹ã‚ã‚‹
                    while len(parts) < 8:
                        parts.append("")
                    return ValidationResult(
                        validation_status=parts[0].strip(),
                        validation_message=parts[1].strip(),
                        corrected_name=parts[2].strip(),
                        corrected_department=parts[3].strip(),
                        corrected_position=parts[4].strip(),
                        corrected_specialty=parts[5].strip(),
                        corrected_licence=parts[6].strip(),
                        corrected_others=parts[7].strip()
                    )
        return None
    
    def _try_space_separated_parsing(self, response_text: str) -> Optional[ValidationResult]:
        """ç¬¬2æ®µéš: ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šè§£æ"""
        lines = response_text.strip().split('\n')
        for line in lines:
            parts = re.split(r'\s{2,}', line.strip())
            if len(parts) >= 8:
                return ValidationResult(
                    validation_status=parts[0].strip(),
                    validation_message=parts[1].strip(),
                    corrected_name=parts[2].strip(),
                    corrected_department=parts[3].strip(),
                    corrected_position=parts[4].strip(),
                    corrected_specialty=parts[5].strip(),
                    corrected_licence=parts[6].strip(),
                    corrected_others=parts[7].strip() if len(parts) > 7 else ""
                )
        return None
    
    def _try_regex_parsing(self, response_text: str) -> Optional[ValidationResult]:
        """ç¬¬3æ®µéš: æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹è§£æ"""
        patterns = [
            r'(VALID|PARTIAL|INVALID|NOTFOUND)\s*[:\-\|]\s*(.+)',
            r'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹[:\s]*([A-Z]+)',
            r'åˆ¤å®š[:\s]*([A-Z]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response_text, re.IGNORECASE)
            if match:
                status = match.group(1).upper()
                if status in ['VALID', 'PARTIAL', 'INVALID', 'NOTFOUND']:
                    return ValidationResult(
                        validation_status=status,
                        validation_message="æ­£è¦è¡¨ç¾æŠ½å‡º",
                        corrected_name="",
                        corrected_department="",
                        corrected_position="",
                        corrected_specialty="",
                        corrected_licence="",
                        corrected_others=""
                    )
        return None
    
    def _try_comma_separated_parsing(self, response_text: str) -> Optional[ValidationResult]:
        """ç¬¬4æ®µéš: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šè§£æ"""
        lines = response_text.strip().split('\n')
        for line in lines:
            if ',' in line:
                parts = [part.strip() for part in line.split(',')]
                if len(parts) >= 8:
                    return ValidationResult(
                        validation_status=parts[0].strip(),
                        validation_message=parts[1].strip(),
                        corrected_name=parts[2].strip(),
                        corrected_department=parts[3].strip(),
                        corrected_position=parts[4].strip(),
                        corrected_specialty=parts[5].strip(),
                        corrected_licence=parts[6].strip(),
                        corrected_others=parts[7].strip() if len(parts) > 7 else ""
                    )
        return None
    
    def _try_natural_language_extraction(self, response_text: str, original_record: pd.Series) -> Optional[ValidationResult]:
        """ç¬¬5æ®µéš: è‡ªç„¶è¨€èªå‡¦ç†ã«ã‚ˆã‚‹æƒ…å ±æŠ½å‡ºï¼ˆæœ€çµ‚æ‰‹æ®µã¨ã—ã¦ä½¿ç”¨ã‚’åˆ¶é™ï¼‰"""
        # è‡ªç„¶è¨€èªæŠ½å‡ºã®ä½¿ç”¨ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        self.validation_stats['natural_language_extractions'] += 1
        
        # è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›
        self.logger.log_warning(
            f"è‡ªç„¶è¨€èªæŠ½å‡ºã‚’ä½¿ç”¨ (fac_id: {original_record.get('fac_id_unif', 'unknown')}, "
            f"name: {original_record.get('name', 'unknown')})"
        )
        
        # ã‚ˆã‚Šå³å¯†ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
        response_lower = response_text.lower()
        
        # æ˜ç¢ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã®ã¿ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åˆ¤å®š
        if any(kw in response_lower for kw in ['invalid', 'ç„¡åŠ¹', 'å­˜åœ¨ã—ãªã„', 'è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“', 'è©²å½“ãªã—']):
            return ValidationResult(
                validation_status="INVALID",
                validation_message="è‡ªç„¶è¨€èªåˆ¤å®š:ç„¡åŠ¹",
                corrected_name="",
                corrected_department="",
                corrected_position="",
                corrected_specialty="",
                corrected_licence="",
                corrected_others=""
            )
        elif any(kw in response_lower for kw in ['partial', 'éƒ¨åˆ†çš„', 'ä¸€éƒ¨']):
            return ValidationResult(
                validation_status="PARTIAL",
                validation_message="è‡ªç„¶è¨€èªåˆ¤å®š:éƒ¨åˆ†ä¸€è‡´",
                corrected_name=original_record.get('name', ''),
                corrected_department=original_record.get('department', ''),
                corrected_position=original_record.get('position', ''),
                corrected_specialty=original_record.get('specialty', ''),
                corrected_licence=original_record.get('licence', ''),
                corrected_others=original_record.get('others', '')
            )
        elif any(kw in response_lower for kw in ['valid', 'æ­£ã—ã„', 'ä¸€è‡´', 'ç¢ºèª']):
            return ValidationResult(
                validation_status="VALID",
                validation_message="è‡ªç„¶è¨€èªåˆ¤å®š:æœ‰åŠ¹",
                corrected_name=original_record.get('name', ''),
                corrected_department=original_record.get('department', ''),
                corrected_position=original_record.get('position', ''),
                corrected_specialty=original_record.get('specialty', ''),
                corrected_licence=original_record.get('licence', ''),
                corrected_others=original_record.get('others', '')
            )
        
        # æ˜ç¢ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯NOTFOUNDã¨ã—ã¦æ‰±ã†
        return ValidationResult(
            validation_status="NOTFOUND",
            validation_message="TSVè§£æå¤±æ•—",
            corrected_name=original_record.get('name', ''),
            corrected_department=original_record.get('department', ''),
            corrected_position="",
            corrected_specialty="",
            corrected_licence="",
            corrected_others=""
        )
    
    def _update_validation_statistics(self, status: str):
        """æ¤œè¨¼çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°"""
        if status == 'VALID':
            self.validation_stats['valid_count'] += 1
        elif status == 'PARTIAL':
            self.validation_stats['partial_count'] += 1
        elif status == 'INVALID':
            self.validation_stats['invalid_count'] += 1
        elif status == 'NOTFOUND':
            self.validation_stats['notfound_count'] += 1
    
    def _log_validation_attempt(self, record: pd.Series, result: ValidationResult):
        """æ¤œè¨¼è©¦è¡Œã®è©³ç´°ãƒ­ã‚°"""
        self.logger.log_info(
            f"æ¤œè¨¼è©³ç´°",
            doctor_name=record.get('name', ''),
            department=record.get('department', ''),
            validation_status=result.validation_status,
            validation_message=result.validation_message,
            processing_time=result.processing_time,
            parsing_attempts=result.parsing_attempts
        )
    
    def _log_parsing_failure(self, response_text: str, attempts: List[str]):
        """è§£æå¤±æ•—ã®è©³ç´°ãƒ­ã‚°"""
        self.logger.log_error(
            f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æå¤±æ•—",
            response_text=response_text[:200] + "..." if len(response_text) > 200 else response_text,
            parsing_attempts=attempts
        )
    
    def _create_error_result(self, record: pd.Series, error_message: str) -> List[Dict[str, Any]]:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®çµæœã‚’ä½œæˆ"""
        result = {
            'fac_id_unif': record.get('fac_id_unif', ''),
            'output_order': record.get('output_order', ''),
            'name': record.get('name', ''),
            'department': record.get('department', ''),
            'position': record.get('position', ''),
            'specialty': record.get('specialty', ''),
            'licence': record.get('licence', ''),
            'others': record.get('others', ''),
            'validation_status': 'NOTFOUND',
            'validation_message': error_message[:20],
            'corrected_name': record.get('name', ''),
            'corrected_department': record.get('department', ''),
            'corrected_position': '',
            'corrected_specialty': '',
            'corrected_licence': '',
            'corrected_others': ''
        }
        
        self.validation_stats['notfound_count'] += 1
        return [result]
    
    def _validation_result_to_dict(self, record: pd.Series, result: ValidationResult) -> Dict[str, Any]:
        """ValidationResultã‚’è¾æ›¸ã«å¤‰æ›ï¼ˆæ­£ã—ã„åˆ—åã§å‡ºåŠ›ï¼‰"""
        from datetime import datetime, timezone, timedelta
        
        # JSTæ™‚åˆ»ã‚’å–å¾—
        jst = timezone(timedelta(hours=9))
        jst_time = datetime.now(jst).strftime('%Y-%m-%d %H:%M:%S')
        
        return {
            'fac_id_unif': record.get('fac_id_unif', ''),
            'url': record.get('url', record.get('URL', '')),  # url ã¾ãŸã¯ URLåˆ—ã‚’æ¢ã™
            'output_order': record.get('output_order', ''),
            # originalãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã®å…ƒãƒ‡ãƒ¼ã‚¿
            'original_name': record.get('name', ''),
            'original_department': record.get('department', ''),
            'original_position': record.get('position', ''),
            'original_specialty': record.get('specialty', ''),
            'original_licence': record.get('licence', ''),
            'original_others': record.get('others', ''),
            # æ¤œè¨¼çµæœ
            'validation_status': result.validation_status,
            'validation_message': result.validation_message,
            # correctedãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã®ä¿®æ­£ãƒ‡ãƒ¼ã‚¿
            'corrected_name': result.corrected_name,
            'corrected_department': result.corrected_department,
            'corrected_position': result.corrected_position,
            'corrected_specialty': result.corrected_specialty,
            'corrected_licence': result.corrected_licence,
            'corrected_others': result.corrected_others,
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            'validation_datetime': jst_time,
            'ai_version': self.config.ai_model  # config.pyã‹ã‚‰å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
        }
    
    async def _save_validation_results(self):
        """æ¤œè¨¼çµæœã‚’ä¿å­˜"""
        try:
            if not self.all_records:
                return
            
            # TSVå½¢å¼ã§ä¿å­˜
            self.gcs_client.upload_tsv(self.all_records)
            
            self.logger.log_success(f"æ¤œè¨¼çµæœä¿å­˜å®Œäº†: {len(self.all_records)}ä»¶")
            
        except Exception as e:
            self.logger.log_error(f"æ¤œè¨¼çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def _log_final_statistics(self):
        """æœ€çµ‚çµ±è¨ˆæƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        total = self.validation_stats['total_processed']
        if total == 0:
            return
        
        # è‡ªç„¶è¨€èªæŠ½å‡ºã®è­¦å‘Š
        nl_count = self.validation_stats.get('natural_language_extractions', 0)
        if nl_count > 0:
            self.logger.log_warning(
                f"âš ï¸ è‡ªç„¶è¨€èªæŠ½å‡ºã‚’{nl_count}å›ä½¿ç”¨ã—ã¾ã—ãŸã€‚"
                f"AIãŒTSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å¿œç­”ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            )
        
        self.logger.log_success(
            "=== åŒ»å¸«æƒ…å ±æ¤œè¨¼çµ±è¨ˆ ===",
            total_processed=total,
            valid_count=self.validation_stats['valid_count'],
            valid_rate=f"{self.validation_stats['valid_count'] / total * 100:.1f}%",
            partial_count=self.validation_stats['partial_count'],
            partial_rate=f"{self.validation_stats['partial_count'] / total * 100:.1f}%",
            invalid_count=self.validation_stats['invalid_count'],
            invalid_rate=f"{self.validation_stats['invalid_count'] / total * 100:.1f}%",
            notfound_count=self.validation_stats['notfound_count'],
            notfound_rate=f"{self.validation_stats['notfound_count'] / total * 100:.1f}%",
            natural_language_extractions=nl_count,
            parsing_failures=self.validation_stats['parsing_failures'],
            processing_errors=self.validation_stats['processing_errors']
        )
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹æ¸…ç†"""
        try:
            # æœ€çµ‚çµ±è¨ˆã‚’å‡ºåŠ›
            self._log_final_statistics()
            
            # ãƒ­ã‚°ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            if hasattr(self, 'gcs_client') and self.gcs_client:
                log_path = self.gcs_client.upload_log()
                if log_path:
                    self.logger.log_success(f"ãƒ­ã‚°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {log_path}")
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            from common.utils import cleanup_memory
            cleanup_memory()
            
            self.logger.log_info("ãƒªã‚½ãƒ¼ã‚¹æ¸…ç†å®Œäº†")
        except Exception as e:
            self.logger.log_warning(f"ãƒªã‚½ãƒ¼ã‚¹æ¸…ç†ã‚¨ãƒ©ãƒ¼: {e}")


def run(config: Config, logger: UnifiedLogger) -> None:
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã®å®Ÿè¡Œé–¢æ•°ï¼ˆç‹¬ç«‹å®Ÿè£…ï¼‰"""
    processor = None
    
    try:
        logger.log_info("DoctorInfoValidationProcessoråˆæœŸåŒ–é–‹å§‹")
        processor = DoctorInfoValidationProcessor(config, logger)
        logger.log_info("DoctorInfoValidationProcessoråˆæœŸåŒ–å®Œäº†")
        
        # éåŒæœŸå‡¦ç†ã‚’æ¨å¥¨ï¼ˆå¤§å­¦ç—…é™¢1000åŒ»å¸«å¯¾å¿œï¼‰
        use_async = os.getenv("USE_ASYNC", "true").lower() == "true"
        logger.log_info(f"å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {'async' if use_async else 'sync'}")
        
        if use_async:
            asyncio.run(processor.run_async())
        else:
            processor.run_sync()
            
    except Exception as e:
        if logger:
            logger.log_error(f"åŒ»å¸«æƒ…å ±æ¤œè¨¼å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            import traceback
            logger.log_error(f"ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:\n{traceback.format_exc()}")
        raise
        
    finally:
        if processor:
            processor.cleanup()